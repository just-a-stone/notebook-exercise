{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_accuracy(a, b, tip):\n",
    "    acc = a.ravel() == b.ravel()\n",
    "    acc_rate = 100 * float(acc.sum()) / a.size\n",
    "    print '%s正确率: %.3f%%' % (tip, acc_rate)\n",
    "    return acc_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_name, is_train):\n",
    "    data = pd.read_csv(file_name)\n",
    "    pd.set_option('display.width', 200)\n",
    "    print 'data.describe()=\\n', data.describe()\n",
    "    \n",
    "    # [性别] 转换为分类变量（可计算）\n",
    "    data['Sex'] = pd.Categorical(data['Sex']).codes\n",
    "    \n",
    "    # 补齐船 [票价] 格缺失值\n",
    "    if len(data.Fare[data.Fare == 0]) > 0:\n",
    "        # 计算不同社会层级各自的平均票价\n",
    "        fare = np.zeros(3)\n",
    "        for f in range(0,3):\n",
    "            fare[f] = data[data['Pclass'] == f + 1]['Fare'].dropna().median()\n",
    "        print fare\n",
    "        # 按社会层级不同，补充缺失值\n",
    "        for i in range(0, 3):\n",
    "            data.loc[(data.Fare == 0) & (data.Pclass == f+1), 'Fare'] = fare[f]\n",
    "            \n",
    "    print 'data.describe() =\\n', data.describe()\n",
    "    \n",
    "    # [年龄] 使用均值代替缺失值\n",
    "    # mean_age = data['Age'].dropna().mean()\n",
    "    # data.loc[(data.Age.isnull()), 'Age'] = mean_age\n",
    "    if is_train:\n",
    "        # [年龄] 使用随机森林预测年龄缺失值\n",
    "        print '随机森林预测缺失年龄：--start--'\n",
    "        data_for_age = data[['Age', 'Survived', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]\n",
    "        print age_exist\n",
    "        \n",
    "        x = age_exist.values[:, 1:]\n",
    "        y = age_exist.values[:, 0]\n",
    "        rfr = RandomForestRegressor(n_estimators=20)\n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n",
    "        print '随机森林预测缺失年龄：--over--'\n",
    "    else:\n",
    "        print '随机森林预测缺失年龄2：--start--'\n",
    "        data_for_age = data[['Age', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]\n",
    "        \n",
    "        x = age_exist.values[:, 1:]\n",
    "        y = age_exist.values[:, 0]\n",
    "        rfr = RandomForestRegressor(n_estimators=1000)\n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n",
    "        print '随机森林预测缺失年龄2：--over--'\n",
    "    data['Age'] = pd.cut(data['Age'], bins=6, labels=np.arange(6))\n",
    "    \n",
    "    # [起始城市] 缺失值打上标记，然后转换为分类变量\n",
    "    data.loc[(data.Embarked.isnull()), 'Embarked'] = 'S'\n",
    "    embarked_data = pd.get_dummies(data.Embarked)\n",
    "    print 'embarked_data =', embarked_data\n",
    "    # embarked_data = embarked_data.rename(columns={'S': 'Southampton', 'C': 'Cherbourg', 'Q': 'Queenstown', 'U': 'UnknownCity'})\n",
    "    embarked_data = embarked_data.rename(columns=lambda x: 'Embarked_' + str(x))\n",
    "    data = pd.concat([data, embarked_data], axis=1)\n",
    "    print u'data.describe() =', data.describe()\n",
    "    \n",
    "    data.to_csv('New_Data.csv')\n",
    "    \n",
    "    x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n",
    "    y = None\n",
    "    if 'Survived' in data:\n",
    "        y = data['Survived']\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # 这里在做啥\n",
    "    x = np.tile(x, (5,1))\n",
    "    y = np.tile(y, (5,))\n",
    "    if is_train:\n",
    "        return x, y\n",
    "    return x, data['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_result(c, c_type):\n",
    "    file_name = 'Titanic.test.csv'\n",
    "    x, passenger_id = load_data(file_name, False)\n",
    "    \n",
    "    if c_type == 3:\n",
    "        x = xgb.DMatrix(x)\n",
    "    y = c.predict(x)\n",
    "    y[y > 0.5] = 1\n",
    "    y[~(y > 0.5)] = 0\n",
    "    \n",
    "    predictions_file = open('Prediction_%d.csv' % c_type, 'wb')\n",
    "    open_file_object = csv.writer(predictions_file)\n",
    "    open_file_object.writerow(['PassengerId', 'Survived'])\n",
    "    open_file_object.writerows(zip(passenger_id, y))\n",
    "    predictions_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.describe()=\n",
      "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "[ 60.2875  14.25     8.05  ]\n",
      "data.describe() =\n",
      "       PassengerId    Survived      Pclass         Sex         Age       SibSp       Parch        Fare\n",
      "count   891.000000  891.000000  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean    446.000000    0.383838    2.308642    0.647587   29.699118    0.523008    0.381594   32.240347\n",
      "std     257.353842    0.486592    0.836071    0.477990   14.526497    1.102743    0.806057   49.672895\n",
      "min       1.000000    0.000000    1.000000    0.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%     223.500000    0.000000    2.000000    0.000000   20.125000    0.000000    0.000000    7.925000\n",
      "50%     446.000000    0.000000    3.000000    1.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%     668.500000    1.000000    3.000000    1.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max     891.000000    1.000000    3.000000    1.000000   80.000000    8.000000    6.000000  512.329200\n",
      "随机森林预测缺失年龄：--start--\n",
      "      Age  Survived      Fare  Parch  SibSp  Pclass\n",
      "0    22.0         0    7.2500      0      1       3\n",
      "1    38.0         1   71.2833      0      1       1\n",
      "2    26.0         1    7.9250      0      0       3\n",
      "3    35.0         1   53.1000      0      1       1\n",
      "4    35.0         0    8.0500      0      0       3\n",
      "6    54.0         0   51.8625      0      0       1\n",
      "7     2.0         0   21.0750      1      3       3\n",
      "8    27.0         1   11.1333      2      0       3\n",
      "9    14.0         1   30.0708      0      1       2\n",
      "10    4.0         1   16.7000      1      1       3\n",
      "11   58.0         1   26.5500      0      0       1\n",
      "12   20.0         0    8.0500      0      0       3\n",
      "13   39.0         0   31.2750      5      1       3\n",
      "14   14.0         0    7.8542      0      0       3\n",
      "15   55.0         1   16.0000      0      0       2\n",
      "16    2.0         0   29.1250      1      4       3\n",
      "18   31.0         0   18.0000      0      1       3\n",
      "20   35.0         0   26.0000      0      0       2\n",
      "21   34.0         1   13.0000      0      0       2\n",
      "22   15.0         1    8.0292      0      0       3\n",
      "23   28.0         1   35.5000      0      0       1\n",
      "24    8.0         0   21.0750      1      3       3\n",
      "25   38.0         1   31.3875      5      1       3\n",
      "27   19.0         0  263.0000      2      3       1\n",
      "30   40.0         0   27.7208      0      0       1\n",
      "33   66.0         0   10.5000      0      0       2\n",
      "34   28.0         0   82.1708      0      1       1\n",
      "35   42.0         0   52.0000      0      1       1\n",
      "37   21.0         0    8.0500      0      0       3\n",
      "38   18.0         0   18.0000      0      2       3\n",
      "..    ...       ...       ...    ...    ...     ...\n",
      "856  45.0         1  164.8667      1      1       1\n",
      "857  51.0         1   26.5500      0      0       1\n",
      "858  24.0         1   19.2583      3      0       3\n",
      "860  41.0         0   14.1083      0      2       3\n",
      "861  21.0         0   11.5000      0      1       2\n",
      "862  48.0         1   25.9292      0      0       1\n",
      "864  24.0         0   13.0000      0      0       2\n",
      "865  42.0         1   13.0000      0      0       2\n",
      "866  27.0         1   13.8583      0      1       2\n",
      "867  31.0         0   50.4958      0      0       1\n",
      "869   4.0         1   11.1333      1      1       3\n",
      "870  26.0         0    7.8958      0      0       3\n",
      "871  47.0         1   52.5542      1      1       1\n",
      "872  33.0         0    5.0000      0      0       1\n",
      "873  47.0         0    9.0000      0      0       3\n",
      "874  28.0         1   24.0000      0      1       2\n",
      "875  15.0         1    7.2250      0      0       3\n",
      "876  20.0         0    9.8458      0      0       3\n",
      "877  19.0         0    7.8958      0      0       3\n",
      "879  56.0         1   83.1583      1      0       1\n",
      "880  25.0         1   26.0000      1      0       2\n",
      "881  33.0         0    7.8958      0      0       3\n",
      "882  22.0         0   10.5167      0      0       3\n",
      "883  28.0         0   10.5000      0      0       2\n",
      "884  25.0         0    7.0500      0      0       3\n",
      "885  39.0         0   29.1250      5      0       3\n",
      "886  27.0         0   13.0000      0      0       2\n",
      "887  19.0         1   30.0000      0      0       1\n",
      "889  26.0         1   30.0000      0      0       1\n",
      "890  32.0         0    7.7500      0      0       3\n",
      "\n",
      "[714 rows x 6 columns]\n",
      "随机森林预测缺失年龄：--over--\n",
      "embarked_data =      C  Q  S  U\n",
      "0    0  0  1  0\n",
      "1    1  0  0  0\n",
      "2    0  0  1  0\n",
      "3    0  0  1  0\n",
      "4    0  0  1  0\n",
      "5    0  1  0  0\n",
      "6    0  0  1  0\n",
      "7    0  0  1  0\n",
      "8    0  0  1  0\n",
      "9    1  0  0  0\n",
      "10   0  0  1  0\n",
      "11   0  0  1  0\n",
      "12   0  0  1  0\n",
      "13   0  0  1  0\n",
      "14   0  0  1  0\n",
      "15   0  0  1  0\n",
      "16   0  1  0  0\n",
      "17   0  0  1  0\n",
      "18   0  0  1  0\n",
      "19   1  0  0  0\n",
      "20   0  0  1  0\n",
      "21   0  0  1  0\n",
      "22   0  1  0  0\n",
      "23   0  0  1  0\n",
      "24   0  0  1  0\n",
      "25   0  0  1  0\n",
      "26   1  0  0  0\n",
      "27   0  0  1  0\n",
      "28   0  1  0  0\n",
      "29   0  0  1  0\n",
      "..  .. .. .. ..\n",
      "861  0  0  1  0\n",
      "862  0  0  1  0\n",
      "863  0  0  1  0\n",
      "864  0  0  1  0\n",
      "865  0  0  1  0\n",
      "866  1  0  0  0\n",
      "867  0  0  1  0\n",
      "868  0  0  1  0\n",
      "869  0  0  1  0\n",
      "870  0  0  1  0\n",
      "871  0  0  1  0\n",
      "872  0  0  1  0\n",
      "873  0  0  1  0\n",
      "874  1  0  0  0\n",
      "875  1  0  0  0\n",
      "876  0  0  1  0\n",
      "877  0  0  1  0\n",
      "878  0  0  1  0\n",
      "879  1  0  0  0\n",
      "880  0  0  1  0\n",
      "881  0  0  1  0\n",
      "882  0  0  1  0\n",
      "883  0  0  1  0\n",
      "884  0  0  1  0\n",
      "885  0  1  0  0\n",
      "886  0  0  1  0\n",
      "887  0  0  1  0\n",
      "888  0  0  1  0\n",
      "889  1  0  0  0\n",
      "890  0  1  0  0\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "data.describe() =        PassengerId    Survived      Pclass         Sex       SibSp       Parch        Fare  Embarked_C  Embarked_Q  Embarked_S  Embarked_U\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
      "mean    446.000000    0.383838    2.308642    0.647587    0.523008    0.381594   32.240347    0.188552    0.086420    0.722783    0.002245\n",
      "std     257.353842    0.486592    0.836071    0.477990    1.102743    0.806057   49.672895    0.391372    0.281141    0.447876    0.047351\n",
      "min       1.000000    0.000000    1.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%     223.500000    0.000000    2.000000    0.000000    0.000000    0.000000    7.925000    0.000000    0.000000    0.000000    0.000000\n",
      "50%     446.000000    0.000000    3.000000    1.000000    0.000000    0.000000   14.454200    0.000000    0.000000    1.000000    0.000000\n",
      "75%     668.500000    1.000000    3.000000    1.000000    1.000000    0.000000   31.000000    0.000000    0.000000    1.000000    0.000000\n",
      "max     891.000000    1.000000    3.000000    1.000000    8.000000    6.000000  512.329200    1.000000    1.000000    1.000000    1.000000\n",
      "x = [[3L 1 1L ..., 0 0 1]\n",
      " [1L 0 2L ..., 1 0 0]\n",
      " [3L 0 1L ..., 0 0 1]\n",
      " ..., \n",
      " [3L 0 1L ..., 0 0 1]\n",
      " [1L 1 1L ..., 1 0 0]\n",
      " [3L 1 2L ..., 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "x, y = load_data('Titanic.train.csv', True)\n",
    "print 'x =', x\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \\\n",
    "                                                   test_size=0.25, \\\n",
    "                                                   random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三种分类模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2')\n",
    "lr.fit(x_train, y_train)\n",
    "y_hat = lr.predict(x_test)\n",
    "lr_acc = accuracy_score(y_test, y_hat)\n",
    "# write_result(lr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestRegressor(n_estimators=100)\n",
    "rfc.fit(x_train, y_train)\n",
    "y_hat = rfc.predict(x_test).astype(np.int)\n",
    "rfc_acc = accuracy_score(y_test, y_hat)\n",
    "# write_result(rfc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-error:0.13465\ttrain-error:0.130201\n",
      "[1]\teval-error:0.126571\ttrain-error:0.102963\n",
      "[2]\teval-error:0.106822\ttrain-error:0.0871\n",
      "[3]\teval-error:0.105027\ttrain-error:0.081712\n",
      "[4]\teval-error:0.105925\ttrain-error:0.07842\n",
      "[5]\teval-error:0.09605\ttrain-error:0.071236\n",
      "[6]\teval-error:0.091562\ttrain-error:0.06974\n",
      "[7]\teval-error:0.087074\ttrain-error:0.06525\n",
      "[8]\teval-error:0.087074\ttrain-error:0.06525\n",
      "[9]\teval-error:0.087971\ttrain-error:0.064951\n",
      "[10]\teval-error:0.087074\ttrain-error:0.063753\n",
      "[11]\teval-error:0.085278\ttrain-error:0.062855\n",
      "[12]\teval-error:0.087971\ttrain-error:0.060461\n",
      "[13]\teval-error:0.087074\ttrain-error:0.06076\n",
      "[14]\teval-error:0.083483\ttrain-error:0.058964\n",
      "[15]\teval-error:0.078097\ttrain-error:0.057767\n",
      "[16]\teval-error:0.078995\ttrain-error:0.058964\n",
      "[17]\teval-error:0.076302\ttrain-error:0.056869\n",
      "[18]\teval-error:0.076302\ttrain-error:0.056869\n",
      "[19]\teval-error:0.070916\ttrain-error:0.054175\n"
     ]
    }
   ],
   "source": [
    "data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "param = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.8,\n",
    "    'silent': 1,\n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "bst = xgb.train(param, data_train, num_boost_round=20, evals=watch_list)\n",
    "y_hat = bst.predict(data_test)\n",
    "# write_result(bst, 3)\n",
    "y_hat[y_hat > 0.5] = 1\n",
    "y_hat[~(y_hat > 0.5)] = 0\n",
    "xgb_acc = accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic回归: 79.892%\n",
      "随机森林: 83.842%\n",
      "XGBoost: 92.908%\n"
     ]
    }
   ],
   "source": [
    "print 'Logistic回归: %.3f%%' % (100 * lr_acc)\n",
    "print '随机森林: %.3f%%' % (100 * rfc_acc)\n",
    "print 'XGBoost: %.3f%%' % (100 * xgb_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
