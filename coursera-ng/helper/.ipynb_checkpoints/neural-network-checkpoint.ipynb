{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoidDerivative(a):\n",
    "    \"\"\"\n",
    "    sigmoid求导\n",
    "    \"\"\"\n",
    "    return np.multiply(a, (1 - a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initTheta(len_in, len_out, epsilon):\n",
    "    \"\"\"初始化一次传递的权重（m,n）\n",
    "    \"\"\"\n",
    "    return np.random.rand(len_in, len_out) * 2 * epsilon - epsilon\n",
    "\n",
    "def initThetas(hiddenNum, unitNum, inputSize, classNum, epsilon):\n",
    "    \"\"\"初始化权值矩阵\n",
    "    \n",
    "    Args:\n",
    "        hiddenNum 隐藏层数\n",
    "        unitNum 每个隐藏层，神经元数目\n",
    "        inputSize 输入层规模\n",
    "        classNum 分类数目\n",
    "        epsilon \n",
    "    Returns:\n",
    "        thetas 权值矩阵\n",
    "    \n",
    "    \"\"\"\n",
    "    hiddens = [unitNum for i in range(hiddenNum)]\n",
    "    units = [inputSize] + hiddens + [classNum]\n",
    "    thetas = []\n",
    "    for idx, unit in enumerate(units):\n",
    "        if idx == len(units) - 1:\n",
    "            break\n",
    "        nextUnit = units[idx + 1]\n",
    "        theta = initTheta(nextUnit, unit + 1, epsilon)\n",
    "        thetas.append(theta)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCost(Thetas, y, theLambda, X=None, a=None):\n",
    "    \"\"\"代价计算\n",
    "    \n",
    "    Args:\n",
    "        Thetas 权值矩阵序列\n",
    "        X 样本\n",
    "        y 标签集\n",
    "        a 各层激活值\n",
    "    Return:\n",
    "        J 预测代价\n",
    "    \"\"\"\n",
    "    m = y.shape[0]\n",
    "    if a is None:\n",
    "        a = fp(Thetas, X)\n",
    "    loss = -np.sum(y.T @ np.log(a[-1]) + (1 - y).T @ np.log(1 - a[-1]))\n",
    "    # 参数正则化-偏置不参与正则化\n",
    "    reg = -np.sum([np.sum(Theta[:, 1:]) for Theta in Thetas])\n",
    "    return (1.0 / m) * loss + (1.0 / (2 * m)) * theLambda * reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fp(Thetas, X):\n",
    "    \"\"\"前向反馈过程\n",
    "    \n",
    "    Args:\n",
    "        Thetas 权值矩阵\n",
    "        X 输入样本\n",
    "    Returns:\n",
    "        a 各层激活向量\n",
    "    \"\"\"\n",
    "    layers = range(len(Thetas) + 1)\n",
    "    layerNum = len(layers)\n",
    "    # 初始化激活向量序列\n",
    "    a  = range(layerNum)\n",
    "    # 前向传播计算各层输出\n",
    "    for i in layers:\n",
    "        if i == 0:\n",
    "            a[i] = X.T\n",
    "        else:\n",
    "            z = Thetas[i - 1] @ a[i - 1]\n",
    "            a[i] = sigmoid(z)\n",
    "        # 除输出层外，需要添加偏置\n",
    "        if i != layerNum - 1:\n",
    "            a[i] = np.concatenate((np.ones((1, a[i].shape[1])), a[i]))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bp(Thetas, a, y, theLambda):\n",
    "    \"\"\"反向传播过程\n",
    "    \n",
    "    Args:\n",
    "        a 激活值\n",
    "        y 标签\n",
    "    Returns:\n",
    "        D 权值梯度\n",
    "    \"\"\"\n",
    "    m = y.shape[0]\n",
    "    layers = range(len(Thetas) + 1)\n",
    "    layerNum = len(layers)\n",
    "    d = range(len(layers))\n",
    "    delta = [np.zeros(Theta.shape) for Theta in Thetas]\n",
    "    for i in layers[::-1]:\n",
    "        if i == 0:\n",
    "            # 输入层不计算误差\n",
    "            break\n",
    "        if i == layerNum - 1:\n",
    "            # 输出层误差\n",
    "            d[i] = a[i] - y.T\n",
    "        else:\n",
    "            # 偏置不参与误差计算\n",
    "            d[i] = np.multiply((Thetas[i][:,1:]).T * d(i + 1), sigmoidDerivative(a[i][1:,:]))\n",
    "    for i in layers[0:layerNum - 1]:\n",
    "        delta[i] = d[i + 1] @ (a[i].T)\n",
    "    D = [np.zeros(Theta.shape) for Theta in Thetas]\n",
    "    for i in range(len(Thetas)):\n",
    "        Theta = Thetas[i]\n",
    "        # 偏置更新\n",
    "        D[i][:, 0] = (1.0 / m) * (delta[i][0:, 0].reshape(1, -1))\n",
    "        # 权值更新\n",
    "        D[i][:, 1:] = (1.0 / m) * (delta[i][0:,1:] + theLambda * Theta[:,1:])\n",
    "        \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
